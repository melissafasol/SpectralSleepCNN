{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5973bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "698dea35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissa/miniconda3/envs/env2023/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/melissa/miniconda3/envs/env2023/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import PIL\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "669df4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "wildtypes = ['S7068', 'S7070', 'S7071', 'S7074', 'S7086', 'S7087', 'S7091', 'S7098', 'S7101']\n",
    "gaps = ['S7063', 'S7064', 'S7069', 'S7072', 'S7075', 'S7076', 'S7088', 'S7092', 'S7094', 'S7096']\n",
    "all_ids = ['S7068', 'S7070', 'S7071', 'S7074', 'S7086', 'S7091', 'S7098', 'S7101',\n",
    "          'S7063', 'S7064', 'S7069', 'S7072', 'S7075', 'S7076', 'S7088', 'S7092', 'S7094', 'S7096']\n",
    "clean_br_states = '/home/melissa/PREPROCESSING/SYNGAP1/cleaned_br_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8da8545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/melissa/PROJECT_DIRECTORIES/EEGFeatureExtraction/Scripts/Preprocessing')\n",
    "%run load_files.py\n",
    "%run filter.py \n",
    "%run constants.py\n",
    "\n",
    "directory_path = '/home/melissa/PREPROCESSING/SYNGAP1/numpyformat_baseline'\n",
    "results_path = '/home/melissa/RESULTS/FINAL_MODEL/Rat/Power/'\n",
    "error_path = '/home/melissa/RESULTS/XGBoost/SYNGAP1/ConnectivityErrors/'\n",
    "\n",
    "\n",
    "syngap_1_ls = [ 'S7088', 'S7092', 'S7094', 'S7098', 'S7068', 'S7074', 'S7076', 'S7071', 'S7075', 'S7101']\n",
    "syngap_2_ls =  ['S7091', 'S7070', 'S7072', 'S7083', 'S7063','S7064', 'S7069', 'S7086', 'S7091']\n",
    "\n",
    "analysis_ls = ['S7101', 'S7088', 'S7092', 'S7094', 'S7098', 'S7068', 'S7074', 'S7076', 'S7071', 'S7075',\n",
    "               'S7091', 'S7070', 'S7072', 'S7083', 'S7063','S7064', 'S7069', 'S7086', 'S7091', 'S7101']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d3e463c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and validation test to save images into separate folders\n",
    "genotypes = ['wildtype' if id in wildtypes else 'gap' for id in all_ids]\n",
    "\n",
    "# Split the IDs into training and validation sets, stratifying by genotype\n",
    "train_ids, val_ids, train_genotypes, val_genotypes = train_test_split(\n",
    "    all_ids, genotypes, test_size=0.2, stratify=genotypes, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "332db0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = '/home/melissa/PROJECT_DIRECTORIES/SpectralSleepCNN/data/train/' \n",
    "val_directory = '/home/melissa/PROJECT_DIRECTORIES/SpectralSleepCNN/data/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fb63fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for animal in all_ids:\n",
    "    if animal in wildtypes:\n",
    "        genotype = 'wt'\n",
    "    elif animal in gaps:\n",
    "        genotype = 'gap'\n",
    "        \n",
    "    clean_br_file = pd.read_pickle(clean_br_states +  f'{animal}_BL1.pkl')\n",
    "\n",
    "    #extract indices only equal to 0, 1, 2\n",
    "    clean_indices = clean_br_file[clean_br_file['brainstate'].isin([0,1,2])].index.to_list()\n",
    "\n",
    "    \n",
    "    load_files = LoadFiles(directory_path, animal)\n",
    "    if animal in syngap_1_ls:\n",
    "        data_1, brain_state_1 = load_files.load_one_analysis_file(start_times_dict = SYNGAP_baseline_start, end_times_dict = SYNGAP_baseline_end)\n",
    "    elif animal in syngap_2_ls:\n",
    "        data_1, data_2, brain_state_1, brain_state_2 = load_files.load_two_analysis_files(start_times_dict = SYNGAP_baseline_start, end_times_dict = SYNGAP_baseline_end)\n",
    "    noise_filter_1 = NoiseFilter(data_1, brain_state_file = brain_state_1, channelvariables = channel_variables,ch_type = 'all')    \n",
    "    bandpass_filtered_data_1 = noise_filter_1.filter_data_type()\n",
    "    eeg_chan = bandpass_filtered_data_1[2, :]\n",
    "    #emg_chan = bandpass_filtered_data_1[:, 14]\n",
    "    \n",
    "    split_eeg_data = np.split(eeg_chan, 17280, axis=0)\n",
    "    #split_emg_data = np.split(emg_chan, 17280, axis = 1)\n",
    "    \n",
    "    clean_counter = 0  # Initialize counter for clean indices\n",
    "    \n",
    "    for idx, epoch in enumerate(split_eeg_data):\n",
    "        if idx not in clean_indices:\n",
    "            pass\n",
    "        else:\n",
    "            \n",
    "            clean_counter += 1  # increment clean index counter\n",
    "            \n",
    "            file_row = clean_br_file.loc[idx]['brainstate']\n",
    "            if file_row == 1:\n",
    "                sleep_state = 'NREM'\n",
    "            elif file_row == 0:\n",
    "                sleep_state = 'wake'\n",
    "            elif file_row == 2:\n",
    "                sleep_state = 'REM'\n",
    "            \n",
    "            dpi = 100  # Dots per inch\n",
    "            pixel_size = 224  # Desired size in pixels\n",
    "            inch_size = pixel_size / dpi \n",
    "            \n",
    "            f_eeg, t_eeg, Sxx_eeg = signal.spectrogram(epoch, fs=250.4, window='hann', scaling='spectrum')\n",
    "             # Plotting spectrogram for EEG\n",
    "            fig = plt.figure(figsize=[inch_size, inch_size])\n",
    "            ax = fig.add_subplot(111)\n",
    "            ax.axes.get_xaxis().set_visible(False)\n",
    "            ax.axes.get_yaxis().set_visible(False)\n",
    "            ax.set_frame_on(False)\n",
    "            \n",
    "            cax = ax.pcolormesh(t_eeg, f_eeg, 10 * np.log10(Sxx_eeg), shading='gouraud')\n",
    "            ax.set_ylabel('Frequency [Hz]')\n",
    "            ax.set_xlabel('Time [sec]')\n",
    "            ax.set_title(f'EEG Spectrogram for Animal {animal} Epoch {idx} Brainstate {sleep_state}')\n",
    "            fig.colorbar(cax, ax=ax, label='Intensity [dB]')\n",
    "            ax.set_ylim(0, 20)  # Limit frequency range if desired\n",
    "            if animal in train_ids:\n",
    "                plt.savefig(train_directory + f'{animal}_{idx}_{genotype}_{sleep_state}.png')\n",
    "                plt.close('all')\n",
    "            elif animal in val_ids:\n",
    "                plt.savefig(val_directory + f'{animal}_{idx}_{genotype}_{sleep_state}.png')\n",
    "                plt.close('all')\n",
    "            if clean_counter >= 1000:\n",
    "                break  # Stop the loop\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22d88c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2023",
   "language": "python",
   "name": "env2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
